# Helm - Package manager for kubernetes

## what is Helm?
- Package manager for kubernetes
    - To package YAML files
        - and distribute them to public and private repositories

- Someone made the package file ones and packages made available so that it can be used by other people while deployment by using same cluster.


# Helm Chart
- Bundle of YAML files
- Create your own helm chart with helm
- push them to helm repository
- download and use existing ones
- Available on ArtifactHUB(public)
## Second Feature:
- Templating Engine
![Templating-Engine.png](/assets/Templating-Engine.png)
```bash
#Template YAML Config
apiVersion: v1
kind: Pod
metadata:
    name: {{ .Values.name }}
spec:
    containers:
    - name: {{ .Values.container.name }}
      image: {{ .Values.container.image }}
      port: {{ .Values.container.port }}
```
--- 

```bash
# values.yaml
name: my-app
container:
    name: my-app-container
    image: my-app-image
    port: 9001
```
![Helm-Chart.png](/assets/Helm-Chart.png)

![Helm-Chart-Structure.png](/assets/Helm-Chart-Structure.png)

```bash
helm install <chartname>
helm upgrade <chartname>
helm rollback <chartname>
```

# Deploying the managed k8s cluster on Linode Kubernetes Engine
![Linode-deploying](/assets/Linode-deploying.png)
## Steps
1. Create kubernetes cluster on LKE.
2. Tap Create and kubernetes, fill details
![LKE-details](/assets/LKE-details.png) 
3. Cluster created. now you need to access it from local setup so access file is named under kubeconfig: test-kubeconfig.yaml, download it, it has credential for cluster and certificate
![LKE-test-kubeconfig](/assets/LKE-test-kubeconfig.png)
![LKE-test-credentials.](/assets/LKE-test-credentials.png)
4. set config locally
```bash
ls
chmod 400 test-kubeconfig.yaml
export KUBECONFIG=test-kubeconfig.yaml
kubectl get node
# Deploy mongodb state in cluster step 2
#1. create all files yourself, 2. Use bundle of config files(HelmChart)
brew install helm

# headover to docs.bitnami.com/kubernetes/infrastructure/kubeapps/get-started/install

helm repo add bitnami https://charts.bitnami.com/bitnami

helm search repo bitnami

helm search repo bitnami/mongodb

helm install mongodb --values helm-mongodb.yaml bitnami/mongodb
helm install [our name] --values [values file name] [chart name]

kubectl get pod
# pod 3 replicas get created

kubectl get all

kubectl get secret

# Next step deploying mongo-express UI which is already running, we need to open the mongodb to external service now it is only internal service by using ingress

# using nginx on helm chart

helm install nginx-ingress ingress-nginx/ingress-nginx --set controller.publishService.enabled=true

# Node balancer is automatically created in linode

# Let's create ingress rule now so it is accesible from browser, you can see external ip address to loadbalancer in image, external ip in image is entry point into a cluster and forward the request based on rules we create
kubectl get svc
![helm-svc.png](/assets/helm-svc.png)
# Add the host name for the rule in helm-ingress.yaml
![helm-host-name.png](/assets/helm-host-name.png)
kubectl apply -f helm-ingress.yaml

![helm-final-deployed.png](/assets/helm-final-deployed.png)
# 1) Browser: hostname configured in ingress rule

# 2) Hostname gets resolved to external IP of NodeBalancer

# 3) Ingress Controller resolved the rule and forwarded request to internal MongoExpress Service

kubectl scale --replicas=0 statefulset/mongodb # on restart when again scaled to 3 it will have same data volumes i.e. persistence

helm ls

helm uninstall mongodb 
```

